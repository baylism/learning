{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hoeffding Inequality\n",
    "Run a computer simulation for flipping 1,000 virtual fair coins. Flip each coin independently 10 times. Focus on 3 coins as follows: C1 is the first coin flipped, Crand is a coin chosen randomly from the 1,000, and Cmin is the coin which had the minimum frequency of heads (pick the earlier one in case of a tie).  \n",
    "  \n",
    "Let V1, Vrand, and Vmin be the fraction of heads obtained for the 3 respective coins out of the 10 tosses.  \n",
    "  \n",
    "Run the experiment 100,000 times in order to get a full distribution of V1, Vrand, and Vmin (note that Crand and Cmin will change from run to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coin_flip(coins, runs):\n",
    "    \"\"\"Return list of random coin flips.\n",
    "    \n",
    "    Initialises empty numy array first. \n",
    "    \n",
    "    coins -- number of coins to be flipped\n",
    "    runs -- number of flips per coin\n",
    "    \"\"\"\n",
    "    result = np.zeros((coins, runs), dtype=np.int)\n",
    "\n",
    "    for x in np.nditer(result, op_flags=['readwrite']):\n",
    "        x[...] = np.random.randint(0, 2)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def coin_flip_2(coins, runs):\n",
    "    \"\"\"Return list of random coin flips.\n",
    "    \n",
    "    Flips coins while constructing list.  \n",
    "    \n",
    "    coins -- number of coins to be flipped\n",
    "    runs -- number of flips per coin\n",
    "    \"\"\"\n",
    "    result = [[np.random.randint(0, 2) for run in range(runs)] for coin in range(coins)]\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def v_1(results):\n",
    "    \"\"\"Return proportion of heads for first coin\"\"\"\n",
    "    return np.mean(results[0])\n",
    "\n",
    "\n",
    "def v_rand(results):\n",
    "    \"\"\"Return proportion of heads for first coin\"\"\"\n",
    "    random_flip = np.random.randint(0, len(results))\n",
    "    return np.mean(results[random_flip])\n",
    "\n",
    "\n",
    "def v_min(results):\n",
    "    \"\"\"Return proportion of heads for coin with fewest heads\"\"\"\n",
    "    head_frequencies = [np.mean(i) for i in results]\n",
    "    return min(head_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coin_experiment(coins, runs, repeats):\n",
    "    v_1_results = []\n",
    "    v_rand_results = []\n",
    "    v_min_results = []\n",
    "\n",
    "    for repeat in range(repeats):\n",
    "        results = coin_flip(coins, runs)\n",
    "        v_1_results.append(v_1(results))\n",
    "        v_rand_results.append(v_rand(results))\n",
    "        v_min_results.append(v_min(results))\n",
    "\n",
    "    v_1_average = np.mean(v_1_results)\n",
    "    v_rand_average = np.mean(v_rand_results)\n",
    "    v_min_average = np.mean(v_min_results)\n",
    "\n",
    "    return v_1_average, v_rand_average, v_min_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.50399999999999989, 0.53799999999999992, 0.12099999999999998)\n"
     ]
    }
   ],
   "source": [
    "result = coin_experiment(100, 10, 100)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the experiments\n",
    "Create a target function f and data set D. Take d = 2 and assume X = [-1, 1] X [-1, 1] with uniform probability of picking each x in X. In each run, choose a random line in the plane as your target function f (do this by taking two random, uniformly distributed points in [-1, 1] X [-1, 1] and taking the line passing through them), where one side of the line maps to +1 and the other maps to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(number_of_points):\n",
    "    \"\"\"Return dataset of random points in form x0=1, x1, x2\"\"\"\n",
    "    ones = np.ones((number_of_points, 1))\n",
    "    points = np.random.uniform(-1.0, 1.0, size=(number_of_points, 2))\n",
    "    return np.concatenate((ones, points), axis=1)\n",
    "\n",
    "\n",
    "def create_f(points):\n",
    "    \"\"\"Return coeficients of random straight line x0=1, m, c\"\"\"\n",
    "    points = np.random.uniform(-1.0, 1.0, size=(points, 2))\n",
    "    p0 = 1.0\n",
    "    b = [-p0, -p0]\n",
    "    w1, w2 = np.linalg.solve(points, b)\n",
    "    return np.array([p0, w1, w2])\n",
    "\n",
    "\n",
    "def evaluate_points(dataset, line):\n",
    "    \"\"\"Return list classifying points in dataset as above or below line\"\"\"\n",
    "\n",
    "    return np.sign(dataset.dot(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define linear regression and error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg(dataset, y):\n",
    "    \"\"\"Return weights from linear regression\"\"\"\n",
    "    pseudo_inverse = np.linalg.pinv(dataset)\n",
    "    w = pseudo_inverse.dot(y)\n",
    "\n",
    "    return w\n",
    "\n",
    "def calculate_error(dataset, weights, y):\n",
    "    \"\"\"Calculate error in weights\"\"\"\n",
    "    output = evaluate_points(dataset, weights)\n",
    "    comparison = np.equal(output, y)\n",
    "\n",
    "    number_false = 0\n",
    "    for c in comparison:\n",
    "        if c == False:\n",
    "            number_false += 1\n",
    "\n",
    "    return number_false / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the experiment\n",
    "Take N = 100. Use Linear Regression to find g and evaluate Ein, the fraction of in-sample points which got classied incorrectly. Repeat the experiment 1000\n",
    "times and take the average (keep the g's as they will be used again in Problem\n",
    "6). Which of the following values is closest to the average Ein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linreg_test(N, repeats):\n",
    "    \"\"\"Reutrn numpy array of shape (repeats, 4).\n",
    "    \n",
    "    Columns:\n",
    "    Weight 1 | Weight 2 | Weight 3 | Error \n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for repeat in range(repeats):\n",
    "        dataset = create_dataset(N)\n",
    "        target_function = create_f(2)\n",
    "        y = evaluate_points(dataset, target_function)\n",
    "        \n",
    "        weights = linreg(dataset, y)\n",
    "        error = calculate_error(dataset, weights, y)\n",
    "        \n",
    "        result = np.append(weights, error)\n",
    "        results.append(result)\n",
    "\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39903932 -0.01444056  0.01219455  0.03935   ]\n"
     ]
    }
   ],
   "source": [
    "results = linreg_test(100, 1000)\n",
    "averages = np.mean(results, axis=0)\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out of sample error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def out_sample_error(weights, target_function, N):\n",
    "    \"\"\"Return out of sample error for weights/target function, over N points\"\"\"\n",
    "\n",
    "    new_points = create_dataset(N)\n",
    "    y = evaluate_points(new_points, target_function)\n",
    "\n",
    "    return calculate_error(new_points, weights, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linreg_test_errors(N, repeats):\n",
    "    \"\"\"Reutrn numpy array of shape (repeats, 5).\n",
    "    \n",
    "    Columns:\n",
    "    Weight 1 | Weight 2 | Weight 3 | Error | Out of sample error\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for repeat in range(repeats):\n",
    "        dataset = create_dataset(N)\n",
    "        target_function = create_f(2)\n",
    "        y = evaluate_points(dataset, target_function)\n",
    "\n",
    "        weights = linreg(dataset, y)\n",
    "        error = calculate_error(dataset, weights, y)\n",
    "        out_error = out_sample_error(weights, target_function, 1000)\n",
    "\n",
    "        result = []\n",
    "        result.append(weights)\n",
    "        result.append(error)\n",
    "        result.append(out_error)\n",
    "\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39903932 -0.01444056  0.01219455  0.03935   ]\n"
     ]
    }
   ],
   "source": [
    "results_2 = linreg_test(100, 1000)\n",
    "averages_2 = np.mean(results, axis=0)\n",
    "print(averages_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron with linear regression\n",
    "After finding the weights using Linear Regression, use them as a vector of initial weights for the Perceptron Learning Algorithm. Run PLA until it converges to a final vector of weights that completely separates\n",
    "all the in-sample points.  \n",
    "  \n",
    "How many iterations (over 1000 runs) does it take for PLA  to converge?  \n",
    "  \n",
    "When implementing PLA, have the algorithm choose a point randomly from\n",
    "the set of misclassiffied points at each iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In addition to the functions defined in 'Setting up the experiments' above, the Perceptron requires a few more functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_points(dataset, line):\n",
    "    \"\"\"Return list classifying points in dataset as above or below line\"\"\"\n",
    "\n",
    "    return np.sign(dataset.dot(line))\n",
    "\n",
    "\n",
    "def create_weights(dataset):\n",
    "    \"\"\"Return empty weight vector of appropriate size for dataset\"\"\"\n",
    "    length = len(dataset[0])\n",
    "    return np.zeros(length, int)\n",
    "\n",
    "\n",
    "def check_classifications(dataset, weights, y):\n",
    "    \"\"\"Return list of misclassified points in dataset\"\"\"\n",
    "    misclassified_points = []\n",
    "\n",
    "    for point_index in range(len(dataset)):\n",
    "        if np.sign(dataset[point_index].dot(weights)) != y[point_index]:\n",
    "            misclassified_points.append(point_index)\n",
    "\n",
    "    return misclassified_points\n",
    "\n",
    "\n",
    "def nudge(dataset, y, weights, misclassified_points):\n",
    "    \"\"\"Update weights using a random misclassified point\"\"\"\n",
    "\n",
    "    point_index = np.random.choice(misclassified_points)\n",
    "\n",
    "    weights = weights + y[point_index] * dataset[point_index]\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running PLA with initial weights found by linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_perceptron_linreg(number_of_points):\n",
    "    \"\"\"Return number of iterations to complete PLA for dataset\"\"\"\n",
    "    dataset = create_dataset(number_of_points)\n",
    "    line = create_f(2)\n",
    "    y = evaluate_points(dataset, line)\n",
    "    \n",
    "    weights = linreg(dataset, y)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        misclassified_points = check_classifications(dataset, weights, y)\n",
    "\n",
    "        if misclassified_points:\n",
    "\n",
    "            weights = nudge(dataset, y, weights, misclassified_points)\n",
    "            count += 1\n",
    "\n",
    "        else: break\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the number of iterations for weights to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.592\n"
     ]
    }
   ],
   "source": [
    "def run_test(repeats, number_of_points):\n",
    "    \"\"\"Return mean number of iterations before PLA converges\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in range(repeats):\n",
    "        results.append(run_perceptron_linreg(number_of_points))\n",
    "\n",
    "    return sum(results)/len(results)\n",
    "\n",
    "print(run_test(1000, 10))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
